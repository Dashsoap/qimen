import { BaseAnalysis, AI_CONFIG, AnalysisStrategy } from './BaseAnalysis.js';
import { 
  getMasterSystemPrompt, 
  buildMasterPrompt, 
  getCurrentTimeInfo 
} from '../../prompts/index.js';

/**
 * ä¸“ä¸šå¤§å¸ˆè§£ç›˜åˆ†æç­–ç•¥
 * æä¾›æœ€ä¸“ä¸šã€æœ€è¯¦ç»†çš„å¥‡é—¨éç”²è§£è¯»
 */
export class MasterAnalysis extends BaseAnalysis {
  constructor() {
    super();
    this.strategyName = AnalysisStrategy.MASTER;
  }

  /**
   * æ‰§è¡Œä¸“ä¸šå¤§å¸ˆè§£ç›˜åˆ†æ
   * @param {string} question - ç”¨æˆ·é—®é¢˜
   * @param {object} parsedPaipan - å·²è§£æçš„æ’ç›˜æ•°æ®
   * @param {object} options - å¯é€‰å‚æ•°
   * @returns {Promise<string>} åˆ†æç»“æœ
   */
  async analyze(question, parsedPaipan, options = {}) {
    console.log('ğŸ¯ å¼€å§‹MASTERæ¨¡å¼åˆ†æ');
    
    const timeInfo = getCurrentTimeInfo();
    const systemPrompt = getMasterSystemPrompt(timeInfo);
    const userPrompt = buildMasterPrompt(question, parsedPaipan);
    
    const response = await this.openai.chat.completions.create({
      model: AI_CONFIG.ARK_MODEL,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      max_tokens: AI_CONFIG.MAX_TOKENS.master,
      temperature: AI_CONFIG.TEMPERATURE.master
    });

    return this.cleanAiResponse(response.choices[0].message.content);
  }
}




